{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.532474Z",
     "iopub.status.busy": "2025-11-12T10:41:14.532110Z",
     "iopub.status.idle": "2025-11-12T10:41:14.538259Z",
     "shell.execute_reply": "2025-11-12T10:41:14.537000Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.532453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.539700Z",
     "iopub.status.busy": "2025-11-12T10:41:14.539455Z",
     "iopub.status.idle": "2025-11-12T10:41:14.569304Z",
     "shell.execute_reply": "2025-11-12T10:41:14.568068Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.539683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class GradCAM1D:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0].detach()\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, x, meta, class_idx=None):\n",
    "        self.model.zero_grad()\n",
    "        out = self.model(x, meta)\n",
    "        if class_idx is None:\n",
    "            class_idx = out.argmax(dim=1).item()\n",
    "        score = out[0, class_idx]\n",
    "        score.backward()\n",
    "        grads = self.gradients.mean(dim=2, keepdim=True)\n",
    "        cam = F.relu((grads * self.activations).sum(dim=1)).squeeze()\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        return cam.cpu().numpy(), class_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.571360Z",
     "iopub.status.busy": "2025-11-12T10:41:14.570622Z",
     "iopub.status.idle": "2025-11-12T10:41:14.591717Z",
     "shell.execute_reply": "2025-11-12T10:41:14.590458Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.571323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import os\n",
    "import os, glob, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.594413Z",
     "iopub.status.busy": "2025-11-12T10:41:14.594126Z",
     "iopub.status.idle": "2025-11-12T10:41:14.623916Z",
     "shell.execute_reply": "2025-11-12T10:41:14.622532Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.594392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN1DGRU(nn.Module):\n",
    "    def __init__(self, in_channels, meta_dim=3, n_classes=5, hidden=128, layers=1, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.gru = nn.GRU(input_size=256, hidden_size=hidden, num_layers=layers,\n",
    "                          bidirectional=bidirectional, batch_first=False)\n",
    "        out_dim = hidden * (2 if bidirectional else 1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(out_dim + meta_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, meta):\n",
    "        x = F.relu(self.bn1(self.conv1(x))); x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x))); x = self.pool2(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x))); x = self.pool3(x)\n",
    "\n",
    "        \n",
    "        \n",
    "        x = x.permute(2,0,1)\n",
    "        out, _ = self.gru(x)\n",
    "        last = out[-1]  \n",
    "        \n",
    "        cat = torch.cat([last, meta], dim=1)\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.626056Z",
     "iopub.status.busy": "2025-11-12T10:41:14.625734Z",
     "iopub.status.idle": "2025-11-12T10:41:14.669322Z",
     "shell.execute_reply": "2025-11-12T10:41:14.667955Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.626029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN1DGRU(\n",
       "  (conv1): Conv1d(40, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (gru): GRU(256, 128, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=259, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_path = \"/kaggle/input/meta-data/Metadata.csv\"\n",
    "meta_df = pd.read_csv(meta_path)\n",
    "\n",
    "\n",
    "meta_df[\"Gender\"] = meta_df[\"Gender\"].map({\"M\": 0, \"F\": 1})\n",
    "\n",
    "\n",
    "meta_df = meta_df[[\"SubjectID\", \"Age\", \"Gender\", \"BMI\", \"Diagnosis\"]]\n",
    "\n",
    "\n",
    "def get_meta_for_patient(file_path, meta_df):\n",
    "    import os\n",
    "    patient_id = os.path.normpath(file_path).split(os.sep)[-3]\n",
    "    \n",
    "   \n",
    "    \n",
    "    meta_df[\"SubjectID\"] = meta_df[\"SubjectID\"].astype(str).str.zfill(2)\n",
    "    row = meta_df.loc[meta_df[\"SubjectID\"] == patient_id].iloc[0]\n",
    "\n",
    "    \n",
    "    meta = torch.tensor([[row[\"Age\"], row[\"Gender\"], row[\"BMI\"]]], dtype=torch.float32)\n",
    "    label = row[\"Diagnosis\"]\n",
    "\n",
    "    return meta, row, label\n",
    "\n",
    "\n",
    "\n",
    "model = CNN1DGRU(in_channels=40, meta_dim=3, n_classes=5)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/beat-model/best_model.pth\", map_location=\"cpu\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.670608Z",
     "iopub.status.busy": "2025-11-12T10:41:14.670338Z",
     "iopub.status.idle": "2025-11-12T10:41:14.676857Z",
     "shell.execute_reply": "2025-11-12T10:41:14.676002Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.670585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from scipy.ndimage import label\n",
    "import openai \n",
    "DURATION_SEC = 20.0\n",
    "TOP_K_REGIONS = 3\n",
    "THRESHOLD_PCT = 0.45  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.678031Z",
     "iopub.status.busy": "2025-11-12T10:41:14.677754Z",
     "iopub.status.idle": "2025-11-12T10:41:14.700514Z",
     "shell.execute_reply": "2025-11-12T10:41:14.699431Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.678008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def cam_to_time_ranges(cam, top_k=3, threshold_pct=0.5):\n",
    "    n_frames = cam.shape[0]\n",
    "    sec_per_frame = DURATION_SEC / n_frames\n",
    "    window = 5\n",
    "    cam_smooth = np.convolve(cam, np.ones(window)/window, mode='same')\n",
    "    cam_norm = (cam_smooth - cam_smooth.min()) / (cam_smooth.max() - cam_smooth.min() + 1e-8)\n",
    "    thr = threshold_pct * cam_norm.max()\n",
    "    mask = cam_norm >= thr\n",
    "    labeled, n_labels = label(mask)\n",
    "    regions = []\n",
    "    for lbl in range(1, n_labels+1):\n",
    "        idxs = np.where(labeled == lbl)[0]\n",
    "        start_frame, end_frame = idxs[0], idxs[-1]\n",
    "        avg_score = cam_norm[idxs].mean()\n",
    "        regions.append((start_frame*sec_per_frame, (end_frame+1)*sec_per_frame, avg_score))\n",
    "    if len(regions) == 0:\n",
    "        peak_idxs = np.argsort(cam_norm)[-top_k:][::-1]\n",
    "        for idx in peak_idxs:\n",
    "            regions.append((max(0, (idx-2))*sec_per_frame, min(n_frames, idx+3)*sec_per_frame, cam_norm[idx]))\n",
    "    regions_sorted = sorted(regions, key=lambda x: x[2], reverse=True)[:top_k]\n",
    "    return regions_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.701567Z",
     "iopub.status.busy": "2025-11-12T10:41:14.701331Z",
     "iopub.status.idle": "2025-11-12T10:41:14.731320Z",
     "shell.execute_reply": "2025-11-12T10:41:14.730169Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.701545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def shap_to_text(shap_values_for_class, feature_names=['Age','Gender','BMI'], top_n=3):\n",
    "    out = []\n",
    "    for i, fname in enumerate(feature_names):\n",
    "        val = float(shap_values_for_class[i])\n",
    "        direction = \"increased\" if val > 0 else \"decreased\"\n",
    "        magnitude = abs(val)\n",
    "        out.append(f\"{fname}: {direction} model probability by {magnitude:.3f}\")\n",
    "    return sorted(out, key=lambda s: -float(s.split()[-1]))[:top_n]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_explanation(patient_id, predicted_class, softmax_prob, cam, shap_values, meta_row, n_files):\n",
    "    regions = cam_to_time_ranges(cam, TOP_K_REGIONS, THRESHOLD_PCT)\n",
    "    meta_text = shap_to_text(shap_values, ['Age','Gender','BMI'])\n",
    "    return {\n",
    "        \"patient_id\": patient_id,\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"probability\": round(float(softmax_prob), 3),\n",
    "        \"meta\": {\n",
    "            \"Age\": float(meta_row[\"Age\"]),\n",
    "            \"Gender\": int(meta_row[\"Gender\"]),\n",
    "            \"BMI\": float(meta_row[\"BMI\"])\n",
    "        },\n",
    "        \"meta_influence\": meta_text,\n",
    "        \"top_time_regions_sec\": [\n",
    "            {\"start\": round(s,2), \"end\": round(e,2), \"score\": round(scr,2)} \n",
    "            for s,e,scr in regions\n",
    "        ],\n",
    "        \"n_samples_used\": n_files,\n",
    "        \"notes\": \"CAM averaged across all patient's samples\"\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def aggregate_cam_for_patient(patient_folder, model, cam_explainer, meta_df):\n",
    "    cams = []\n",
    "    patient_id = os.path.basename(patient_folder)\n",
    "    files = []\n",
    "    for root, _, fnames in os.walk(patient_folder):\n",
    "        for f in fnames:\n",
    "            if f.endswith(\".npy\"):\n",
    "                fpath = os.path.join(root, f)\n",
    "                x = torch.tensor(np.load(fpath), dtype=torch.float32).unsqueeze(0)\n",
    "                meta, _ = get_meta_for_patient(fpath, meta_df)\n",
    "                cam, _ = cam_explainer.generate(x, meta)\n",
    "                cams.append(cam)\n",
    "                files.append(fpath)\n",
    "    cam_mean = np.mean(cams, axis=0)\n",
    "    return cam_mean, files, patient_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.732405Z",
     "iopub.status.busy": "2025-11-12T10:41:14.732096Z",
     "iopub.status.idle": "2025-11-12T10:41:14.897074Z",
     "shell.execute_reply": "2025-11-12T10:41:14.895977Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.732375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9441e87c3d444fa9aeb14f21c5bd7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation JSON ready ✅\n",
      "{'patient_id': '01', 'predicted_class': 'Infection', 'probability': 1.0, 'meta': {'Age': 59.0, 'Gender': 0, 'BMI': 31.3}, 'meta_influence': ['Age: increased model probability by 0.003', 'BMI: decreased model probability by 0.003', 'Gender: increased model probability by 0.000'], 'top_time_regions_sec': [{'start': 16.41, 'end': 19.87, 'score': 0.73}, {'start': 12.82, 'end': 14.36, 'score': 0.67}, {'start': 10.0, 'end': 11.79, 'score': 0.65}], 'n_samples_used': 1, 'notes': \"CAM averaged across all patient's samples\"}\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/kaggle/input/data-aug-20-secs/augmented_data/04/DIAP/04_05_AAL.npy\"\n",
    "meta_df = pd.read_csv(\"/kaggle/input/meta-data/Metadata.csv\")\n",
    "meta_df[\"Gender\"] = meta_df[\"Gender\"].map({\"M\":0,\"F\":1})\n",
    "\n",
    "\n",
    "meta, meta_row, true_label = get_meta_for_patient(file_path, meta_df)\n",
    "\n",
    "x = torch.tensor(np.load(file_path), dtype=torch.float32).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    logits = model(x, meta)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "pred_idx = probs.argmax(dim=1).item()\n",
    "pred_class = [\"COPD\",\"ILD\",\"Asthma\",\"Healthy\",\"Infection\"][pred_idx]\n",
    "softmax_prob = probs[0, pred_idx].item()\n",
    "cam_explainer = GradCAM1D(model, model.conv3)\n",
    "cam, _ = cam_explainer.generate(x, meta)\n",
    "\n",
    "# SHAP\n",
    "def predict_fn(meta_np):\n",
    "    meta_t = torch.tensor(meta_np, dtype=torch.float32)\n",
    "    x_t = x.repeat(len(meta_t), 1, 1)\n",
    "    with torch.no_grad():\n",
    "        out = model(x_t, meta_t)\n",
    "        return F.softmax(out, dim=1).numpy()\n",
    "\n",
    "background = np.array([[40,0,22],[55,1,27],[30,0,19]])\n",
    "patient_meta = meta.numpy()\n",
    "explainer = shap.KernelExplainer(predict_fn, background)\n",
    "shap_values_all = explainer.shap_values(patient_meta)\n",
    "shap_values_for_class = shap_values_all[pred_idx][0]\n",
    "\n",
    "#JSON\n",
    "explanation = build_explanation(\n",
    "    patient_id=\"01\",\n",
    "    predicted_class=pred_class,\n",
    "    softmax_prob=softmax_prob,\n",
    "    cam=cam,\n",
    "    shap_values=shap_values_for_class,\n",
    "    meta_row=meta_row,\n",
    "    n_files=1\n",
    ")\n",
    "\n",
    "print(\"Explanation JSON ready ✅\")\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T10:41:14.898938Z",
     "iopub.status.busy": "2025-11-12T10:41:14.898619Z",
     "iopub.status.idle": "2025-11-12T10:41:19.847669Z",
     "shell.execute_reply": "2025-11-12T10:41:19.846751Z",
     "shell.execute_reply.started": "2025-11-12T10:41:14.898916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Generated Explanation -----------\n",
      "**1) Summary:**  \n",
      "The model predicts **Infection** with high confidence (probability: 1.0). Key spectrogram findings highlight specific time regions (16.41–19.87 sec, 12.82–14.36 sec, 10.0–11.79 sec) with high scores (0.73, 0.67, 0.65, respectively), suggesting potential pathological features in these segments.  \n",
      "\n",
      "**2) Findings:**  \n",
      "- **16.41–19.87 sec:** Highest score (0.73), indicating prominent features in this region that strongly contributed to the infection prediction.  \n",
      "- **12.82–14.36 sec:** Moderate score (0.67), suggesting additional pathological patterns in this segment.  \n",
      "- **10.0–11.79 sec:** Score of 0.65, indicating less prominent but still relevant features in this time region.  \n",
      "\n",
      "**3) Metadata Influence:**  \n",
      "- **Age (59 years):** Slightly increased the model’s probability of predicting infection (+0.003).  \n",
      "- **BMI (31.3):** Slightly decreased the model’s probability of predicting infection (-0.003).  \n",
      "- **Gender (Female):** Had a negligible effect on the model’s probability (+0.000).  \n",
      "\n",
      "**4) Suggested Next Steps:**  \n",
      "- Review the spectrogram regions (16.41–19.87 sec, 12.82–14.36 sec, 10.0–11.79 sec) in detail to correlate with clinical symptoms and other diagnostic findings.  \n",
      "- Consider additional tests or imaging to confirm or rule out infection, given\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import cohere\n",
    "\n",
    "\n",
    "co = cohere.Client(api_key=\"pKWl8GY0J7B9n8ZTTZcXykgsgUWV6g729gzx0oAn\")\n",
    "\n",
    "system_msg = (\n",
    "    \"You are an expert clinical AI assistant. Convert model XAI outputs \"\n",
    "    \"into a concise, clinician-friendly explanation. Never make a definitive diagnosis. \"\n",
    "    \"Always add a disclaimer asking for clinical confirmation.\"\n",
    ")\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Input (JSON):\n",
    "{explanation}\n",
    "\n",
    "Produce:\n",
    "1) Summary: predicted class & key spectrogram findings.\n",
    "2) Findings: 3 bullets describing time regions (frequency/time interpretation).\n",
    "3) Metadata influence: bullets summarizing age/gender/bmi effects.\n",
    "4) Suggested next steps: 2 bullets.\n",
    "5) Disclaimer sentence.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-xlarge-nightly\", \n",
    "    message=user_prompt,\n",
    "    preamble=system_msg,\n",
    "    temperature=0.3,\n",
    "    max_tokens=400\n",
    ")\n",
    "\n",
    "print(\"----------- Generated Explanation -----------\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8366176,
     "sourceId": 13200831,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8386161,
     "sourceId": 13230222,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8708384,
     "sourceId": 13691672,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
